{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RjmgXrK5X8WY"},"outputs":[],"source":["# importing the required libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from keras import Sequential\n","# For Transfer Learning\n","from keras.applications.vgg19 import VGG19\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizer_v2.adam import Adam\n","from keras.layers import Flatten, Dense, BatchNormalization, Activation, Dropout\n","from keras.utils.np_utils import to_categorical\n","# Keras library for CIFAR-10 dataset\n","from keras.datasets import cifar10"]},{"cell_type":"markdown","metadata":{"id":"pqyNEEsdX_wN"},"source":["# **Load the dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JsSPs6JX9ut"},"outputs":[],"source":["# Downloading the CIFAR dataset\n","(x_train,y_train),(x_test,y_test)=cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1663770560336,"user":{"displayName":"Tanmay Bhatt","userId":"11681573484210707767"},"user_tz":-330},"id":"0AT4yEBOYCpz","outputId":"bbec2adf-9d66-4743-8d42-687aef1e72f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["((50000, 32, 32, 3), (50000, 10))\n","((12500, 32, 32, 3), (12500, 10, 2))\n","((10000, 32, 32, 3), (10000, 10))\n"]}],"source":["# One Hot Encoding\n","y_train=to_categorical(y_train)\n","y_val=to_categorical(y_val)\n","y_test=to_categorical(y_test)\n","# Verifying the dimension after one hot encoding\n","print((x_train.shape,y_train.shape))\n","print((x_val.shape,y_val.shape))\n","print((x_test.shape,y_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"EAXuuUGKYYH1"},"source":["As you can see we have successfully converted the target variable into a one-hot encoding representation. Now letâ€™s use the ImageDataGenerator module to create the batches of the images so that while training we can feed data sequentially. Below, we will initiate the separate data generator function for each phase, that is training, testing, and validation. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"plMlLyu0YL_w"},"outputs":[],"source":["# Image Data Augmentation\n","train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n","val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n","test_generator = ImageDataGenerator()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jl79S6g_YcrM"},"outputs":[],"source":["# Fitting the augmentation defined above to the data\n","train_generator.fit(x_train)\n","val_generator.fit(x_val)\n","test_generator.fit(x_test)"]},{"cell_type":"markdown","metadata":{"id":"5P_9TzacYfPO"},"source":["# **Loading and training VGG19**"]},{"cell_type":"markdown","metadata":{"id":"FX0O9jX4YleQ"},"source":["Now we will start with building the model, first, we will initialize the rained model that VGG-19 with pre-trained weights from the ImageNet competition."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1ABs0u2YiBG"},"outputs":[],"source":["# Defining the VGG Convolutional Neural Net\n","base_model = VGG19(include_top = False, weights = 'imagenet',\n","                input_shape = (32,32,3), classes = y_train.shape[1])"]},{"cell_type":"markdown","metadata":{"id":"1FuP_vycYrXR"},"source":["Above is the base model that we have initialized, now we will add the last classifier model on top of the above model. Below we will first create Keras sequential model and will first add the base model that is the VGG-19 model and latter will add 4 dense layers with activation function as ReLU and the last layer will be the classifier layer with 10 units and softmax as the activation function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwc6_MHAYnsh"},"outputs":[],"source":["# Adding the final layers to the above base models where the actual classification is done in the dense layers\n","model= Sequential()\n","model.add(base_model)\n","model.add(Flatten())\n","#Adding the Dense layers along with activation and batch normalization\n","model.add(Dense(1024,activation=('relu'),input_dim=512))\n","model.add(Dense(512,activation=('relu')))\n","model.add(Dense(256,activation=('relu')))\n","model.add(Dropout(.3))\n","model.add(Dense(128,activation=('relu')))\n","model.add(Dropout(.2))\n","model.add(Dense(10,activation=('softmax')))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1663770562937,"user":{"displayName":"Tanmay Bhatt","userId":"11681573484210707767"},"user_tz":-330},"id":"3roeJXQ0Yvru","outputId":"16408ca1-e02e-43e3-f220-51490e4e8490"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n","                                                                 \n"," flatten_1 (Flatten)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dense_6 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dense_7 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dropout_3 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 21,240,010\n","Trainable params: 21,240,010\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Checking the final model summary\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"OVKjzmx0Yz_J"},"source":["As we can see there are a total of 21240010 parameters to be trained. Now we will initialize the hyperparameter of the model such as batch size, epochs, and learning rate."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RupAR6FAYxX1"},"outputs":[],"source":["# Initializing the hyperparameters\n","batch_size= 100\n","epochs=50\n","learn_rate=.001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffR1F6NeY4ws"},"outputs":[],"source":["adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['acc'])"]},{"cell_type":"markdown","metadata":{"id":"sncP_YIPY9s9"},"source":["Below we will start the training model, the model will train for the 50 epochs and for each epoch 375 samples will be utilized.  "]},{"cell_type":"markdown","metadata":{"id":"uI-St-55ZBcX"},"source":["# **Training the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"lTy5J5heY6tt","executionInfo":{"status":"error","timestamp":1663780639401,"user_tz":-330,"elapsed":24941,"user":{"displayName":"Tanmay Bhatt","userId":"11681573484210707767"}},"outputId":"b7f0dacc-8832-4336-9bad-987c7129eec8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  after removing the cwd from sys.path.\n"]},{"output_type":"stream","name":"stdout","text":["\r  1/500 [..............................] - ETA: 1:35:41 - loss: 2.3001 - acc: 0.1600"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-a1cbae1d3111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit_generator(train_generator.flow(x_train, y_train, batch_size= 100), epochs = epochs,\n\u001b[1;32m      3\u001b[0m                  \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                  validation_data = val_generator.flow(x_val, y_val, batch_size = 100))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Training the model\n","history = model.fit_generator(train_generator.flow(x_train, y_train, batch_size= 100), epochs = epochs,\n","                 steps_per_epoch = x_train.shape[0]//batch_size,\n","                 validation_data = val_generator.flow(x_val, y_val, batch_size = 100))"]},{"cell_type":"markdown","metadata":{"id":"F-twruSTZHOk"},"source":["# **Evaluating the model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xCfV2jLZOIL"},"outputs":[],"source":["plt.figure(figsize=(12,5))\n","plt.subplot(1,2,1)\n","plt.plot(history.history['loss'],color='b',label='Training Loss')\n","plt.plot(history.history['val_loss'],color='r',label='Validation Loss')\n","plt.legend()\n","plt.subplot(1,2,2)\n","plt.plot(history.history['acc'],color='b',label='Training Loss')\n","plt.plot(history.history['val_acc'],color='r',label='Validation Loss')\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxmzg7OrZQfu"},"outputs":[],"source":["# Making prediction\n","y_pred=model.predict(x_test)\n","y_pred = np.argmax(y_pred,axis=1)\n","y_true=np.argmax(y_test,axis=1)"]},{"cell_type":"markdown","metadata":{"id":"udXNnR8_ZW6c"},"source":["Below we are defining the function which will plot the confusion metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkM8xWe0ZSwK"},"outputs":[],"source":["# Defining function for confusion matrix plot\n","def plot_confusion_matrix(y_true, y_pred, classes,\n","                       normalize=False,\n","                       title=None,\n","                       cmap=plt.cm.Blues):\n","if not title:\n","     if normalize:\n","         title = 'Normalized confusion matrix'\n","     else:\n","         title = 'Confusion matrix, without normalization'\n","# Compute confusion matrix\n","cm = confusion_matrix(y_true, y_pred)\n","if normalize:\n","     cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","     print(\"Normalized confusion matrix\")\n","else:\n","     print('Confusion matrix, without normalization')\n","# print (confusion matrix)\n","fig, ax = plt.subplots(figsize=(7,7))\n","im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n","ax.figure.colorbar(im, ax=ax)\n","# We want to show all ticks...\n","ax.set(xticks=np.arange(cm.shape[1]),\n","        yticks=np.arange(cm.shape[0]),\n","        # ... and label them with the respective list entries\n","        xticklabels=classes, yticklabels=classes,\n","        title=title,\n","        ylabel='True label',\n","        xlabel='Predicted label')\n","#Rotate the tick labels and set their alignment.\n","plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","          rotation_mode=\"anchor\")\n","# Loop over data dimensions and create text annotations.\n","fmt = '.2f' if normalize else 'd'\n","thresh = cm.max() / 2.\n","for i in range(cm.shape[0]):\n","     for j in range(cm.shape[1]):\n","         ax.text(j, i, format(cm[i, j], fmt),\n","                 ha=\"center\", va=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","fig.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"5ic2jarTZeDO"},"source":["Now after defining the function First, we will see the exact number of correct and incorrect classifications using the non-normalized confusion matrix and then we will see the same percentage using the normalized confusion matrix. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CFoH2YHZdZr"},"outputs":[],"source":["np.set_printoptions(precision=2)\n","# Plotting the confusion matrix\n","confusion_mtx = confusion_matrix(y_true, y_pred)\n","# Defining the class labels\n","class_names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","# Plotting non-normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred, classes = class_names, title='Confusion matrix, without normalization')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-YPJHqXZkVM"},"outputs":[],"source":["# Plotting normalized confusion matrix\n","plot_confusion_matrix(y_true, y_pred, classes = class_names, normalize = True, title = 'Normalized confusion matrix')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfN8YkMqZmaw"},"outputs":[],"source":["# Classification report\n","from sklearn.metrics import classification_report\n","print((classification_report(y_pred, np.argmax(y_test,axis=1))))"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPichZIwpc7BjagpEqXwAGU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}